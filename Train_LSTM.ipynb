{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biahoi/BiaHoiDoubleOrNothing.github.io/blob/master/Train_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd73f800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd73f800",
        "outputId": "3c5fb54d-d8dd-4ee1-e8d0-cc91cf07801e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6ms/step - accuracy: 0.6316 - loss: 0.6258 - val_accuracy: 0.7040 - val_loss: 0.5684\n",
            "Epoch 2/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6ms/step - accuracy: 0.6925 - loss: 0.5750 - val_accuracy: 0.6702 - val_loss: 0.5887\n",
            "Epoch 3/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6ms/step - accuracy: 0.6950 - loss: 0.5725 - val_accuracy: 0.7012 - val_loss: 0.5683\n",
            "Epoch 4/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6ms/step - accuracy: 0.6986 - loss: 0.5688 - val_accuracy: 0.7087 - val_loss: 0.5614\n",
            "Epoch 5/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6ms/step - accuracy: 0.6988 - loss: 0.5688 - val_accuracy: 0.7064 - val_loss: 0.5618\n",
            "Epoch 6/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6ms/step - accuracy: 0.6996 - loss: 0.5678 - val_accuracy: 0.7078 - val_loss: 0.5602\n",
            "Epoch 7/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6ms/step - accuracy: 0.6999 - loss: 0.5666 - val_accuracy: 0.6920 - val_loss: 0.5708\n",
            "Epoch 8/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6ms/step - accuracy: 0.7002 - loss: 0.5664 - val_accuracy: 0.7083 - val_loss: 0.5600\n",
            "Epoch 9/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6ms/step - accuracy: 0.7018 - loss: 0.5641 - val_accuracy: 0.6890 - val_loss: 0.5744\n",
            "Epoch 10/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6ms/step - accuracy: 0.7019 - loss: 0.5636 - val_accuracy: 0.7061 - val_loss: 0.5598\n",
            "Epoch 11/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6ms/step - accuracy: 0.7031 - loss: 0.5634 - val_accuracy: 0.7088 - val_loss: 0.5596\n",
            "Epoch 12/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6ms/step - accuracy: 0.7031 - loss: 0.5633 - val_accuracy: 0.6903 - val_loss: 0.5745\n",
            "Epoch 13/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 6ms/step - accuracy: 0.7043 - loss: 0.5620 - val_accuracy: 0.7025 - val_loss: 0.5627\n",
            "Epoch 14/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6ms/step - accuracy: 0.7049 - loss: 0.5615 - val_accuracy: 0.7093 - val_loss: 0.5573\n",
            "Epoch 15/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6ms/step - accuracy: 0.7035 - loss: 0.5627 - val_accuracy: 0.7035 - val_loss: 0.5626\n",
            "Epoch 16/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6ms/step - accuracy: 0.7076 - loss: 0.5583 - val_accuracy: 0.6992 - val_loss: 0.5647\n",
            "Epoch 17/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6ms/step - accuracy: 0.7061 - loss: 0.5596 - val_accuracy: 0.7007 - val_loss: 0.5650\n",
            "Epoch 18/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6ms/step - accuracy: 0.7068 - loss: 0.5574 - val_accuracy: 0.7112 - val_loss: 0.5553\n",
            "Epoch 19/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6ms/step - accuracy: 0.7054 - loss: 0.5598 - val_accuracy: 0.7064 - val_loss: 0.5590\n",
            "Epoch 20/20\n",
            "\u001b[1m11880/11880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6ms/step - accuracy: 0.7069 - loss: 0.5582 - val_accuracy: 0.7105 - val_loss: 0.5537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "Predicted Labels: [[0.6744792 ]\n",
            " [0.69257694]\n",
            " [0.61296386]\n",
            " [0.6331174 ]\n",
            " [0.6140439 ]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Load your DataFrame (Replace with actual data loading)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/TrainData/1740199008_1day_NadarPeakParams_250222_Bot11_Params_1.csv\", index_col=0, parse_dates=True)  # Ensure datetime index\n",
        "\n",
        "# Split features and labels\n",
        "X = df.drop(columns=[\"NADAR_mid_onePeak_trend\"])\n",
        "y = df[\"NADAR_mid_onePeak_trend\"]\n",
        "\n",
        "# Map labels to 0 and 1\n",
        "y = y.map({-1: 0, 1: 1})\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape for LSTM (samples, timesteps, features)\n",
        "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    LSTM(50),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the trained model and scaler\n",
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/LSTM_model/bot11_lstm_model.h5\")\n",
        "joblib.dump(scaler, \"/content/drive/MyDrive/Colab Notebooks/LSTM_model/scaler.pkl\")\n",
        "\n",
        "# Load model and scaler once\n",
        "global_model = load_model(\"/content/drive/MyDrive/Colab Notebooks/LSTM_model/bot11_lstm_model.h5\")\n",
        "global_scaler = joblib.load(\"/content/drive/MyDrive/Colab Notebooks/LSTM_model/scaler.pkl\")\n",
        "\n",
        "# Function to predict label for new data\n",
        "def predict_label(new_data: pd.DataFrame):\n",
        "    new_data_scaled = global_scaler.transform(new_data)\n",
        "    new_data_reshaped = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
        "    predictions = global_model.predict(new_data_reshaped)\n",
        "\n",
        "    # Apply threshold and map to -1 or 1\n",
        "    predicted_labels = [1 if pred >= 0.5 else -1 for pred in predictions]\n",
        "\n",
        "    return predicted_labels\n",
        "\n",
        "# Example usage with new data\n",
        "new_data = pd.DataFrame(np.random.rand(5, X.shape[1]), columns=X.columns)  # Replace with actual new data\n",
        "predictions = predict_label(new_data)\n",
        "print(\"Predicted Labels:\", predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILYCY8TtH4K2",
        "outputId": "8f95e5e1-1aab-4479-f32a-d09248ef84b2"
      },
      "id": "ILYCY8TtH4K2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFy4tRT4Cg-z",
        "outputId": "5f019189-4cf3-49e7-a307-9c659170afb9"
      },
      "id": "CFy4tRT4Cg-z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object `it` not found.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}